version: "0.1"

metadata:
  name: "Real-Time Analytics Data Pipeline"
  description: "ETL pipeline processing customer behavior data for business intelligence"
  author: "Data Engineering Team"
  version: "3.2.1"
  created: "2024-03-10"
  updated: "2025-01-08"
  organization: "DataCo Analytics"
  environment: "production"
  tags:
    - "data-pipeline"
    - "analytics"
    - "etl"
    - "real-time"

applications:
  - id: "data-ingestion"
    name: "Data Ingestion Service"
    type: "data-pipeline"
    technology: "Apache Kafka"
    description: "Ingests clickstream and transaction data"
    owner: "Data Engineering"

  - id: "stream-processor"
    name: "Stream Processing"
    type: "data-pipeline"
    technology: "Apache Flink on EMR"
    description: "Real-time stream processing and enrichment"
    owner: "Data Engineering"

  - id: "batch-etl"
    name: "Batch ETL Jobs"
    type: "batch-job"
    technology: "Apache Spark"
    description: "Daily batch processing of historical data"
    owner: "Data Engineering"

  - id: "ml-training"
    name: "ML Model Training"
    type: "ml-model"
    technology: "SageMaker + PyTorch"
    description: "Customer churn prediction model"
    owner: "Data Science Team"

  - id: "bi-dashboard"
    name: "Business Intelligence Dashboard"
    type: "frontend"
    technology: "QuickSight"
    description: "Executive dashboards and reports"
    owner: "Analytics Team"

infrastructure:
  clouds:
    - id: "aws-analytics-prod"
      provider: "aws"
      region: "us-east-1"
      account_id: "555666777888"
      vpc_id: "vpc-analytics-prod"
      tier: "primary"
      
      services:
        # Data Ingestion Layer
        - id: "kinesis-clickstream"
          service: "kinesis-streams"
          name: "Clickstream Data Stream"
          description: "Ingests real-time clickstream events"
          runs: ["data-ingestion"]
          configuration:
            storage_gb: 2000
          cost:
            monthly_estimate: 450
            currency: "USD"
            breakdown:
              - "Shard hours: 20 shards × 730 hrs × $0.015 = $219"
              - "PUT payload units: 100M × $0.014/M = $1.40"
              - "Extended retention (7 days): 20 shards × 730 hrs × $0.020 = $292"
            pricing_model: "on-demand"

        - id: "kinesis-transactions"
          service: "kinesis-streams"
          name: "Transaction Data Stream"
          description: "Ingests payment and order transactions"
          runs: ["data-ingestion"]
          configuration:
            storage_gb: 1000
            encryption_enabled: true
          cost:
            monthly_estimate: 285
            currency: "USD"
            breakdown:
              - "Shard hours: 10 shards × 730 hrs × $0.015 = $110"
              - "PUT payload units: 50M × $0.014/M = $0.70"
              - "Extended retention (7 days): 10 shards × 730 hrs × $0.020 = $146"
              - "Encryption: ~$28.30"
            pricing_model: "on-demand"
          compliance:
            - "PCI-DSS"

        - id: "kinesis-firehose-s3"
          service: "kinesis-firehose"
          name: "Raw Data Delivery"
          description: "Delivers raw data to S3 data lake"
          configuration:
            storage_gb: 5000
          cost:
            monthly_estimate: 320
            currency: "USD"
            breakdown:
              - "Data ingestion: 5TB × $0.029/GB = $145"
              - "Format conversion (Parquet): 5TB × $0.018/GB = $90"
              - "Data delivery to S3: 5TB × $0.017/GB = $85"
            pricing_model: "on-demand"

        # Stream Processing Layer
        - id: "emr-flink-cluster"
          service: "emr"
          name: "Flink Processing Cluster"
          description: "EMR cluster running Apache Flink for stream processing"
          runs: ["stream-processor"]
          configuration:
            instance_type: "m5.2xlarge"
            instance_count: 8
            auto_scaling:
              enabled: true
              min: 4
              max: 16
              target_cpu: 75
            vpc_enabled: true
          availability_zones:
            - "us-east-1a"
            - "us-east-1b"
          cost:
            monthly_estimate: 3200
            currency: "USD"
            breakdown:
              - "EC2 instances: 8 × m5.2xlarge × 730 hrs × $0.384 = $2,243"
              - "EMR charges: 8 × 730 hrs × $0.135 = $788"
              - "EBS storage: 8 × 500GB × $0.10 = $400"
              - "Additional scaling overhead: -$231"
            pricing_model: "on-demand"

        # Batch Processing Layer
        - id: "glue-etl"
          service: "glue"
          name: "Glue ETL Jobs"
          description: "Serverless ETL for data transformation"
          runs: ["batch-etl"]
          cost:
            monthly_estimate: 850
            currency: "USD"
            breakdown:
              - "DPU-hours: 2000 DPU-hours × $0.44 = $880"
              - "Data Catalog storage: 10M objects × $1/M = $10"
              - "Requests: 1M × $1/M = $1"
              - "Free tier discount: -$41"
            pricing_model: "on-demand"

        - id: "emr-spark-batch"
          service: "emr"
          name: "Spark Batch Jobs"
          description: "EMR for large-scale batch processing"
          runs: ["batch-etl"]
          configuration:
            instance_type: "r5.4xlarge"
            instance_count: 20
          cost:
            monthly_estimate: 1850
            currency: "USD"
            breakdown:
              - "On-demand instances: 20 × r5.4xlarge × 120 hrs/month × $1.008 = $2,419"
              - "Spot instances (70% discount): -$1,693"
              - "EMR charges: 20 × 120 hrs × $0.135 = $324"
              - "EBS storage: 20 × 1TB × $0.10 = $2,000"
              - "Optimization: -$1,200"
            pricing_model: "spot"

        # Storage Layer
        - id: "s3-data-lake-raw"
          service: "s3"
          name: "Raw Data Lake"
          description: "Stores raw ingested data"
          configuration:
            storage_gb: 50000
            encryption_enabled: true
            backup_enabled: false
          tags:
            DataClassification: "raw"
            Retention: "90days"
          cost:
            monthly_estimate: 1150
            currency: "USD"
            breakdown:
              - "Standard storage: 50TB × $0.023/GB = $1,150"
            pricing_model: "on-demand"

        - id: "s3-data-lake-processed"
          service: "s3"
          name: "Processed Data Lake"
          description: "Stores transformed and curated data"
          configuration:
            storage_gb: 100000
            storage_type: "standard"
            encryption_enabled: true
          tags:
            DataClassification: "processed"
            Retention: "7years"
          cost:
            monthly_estimate: 2300
            currency: "USD"
            breakdown:
              - "Standard storage: 100TB × $0.023/GB = $2,300"
            pricing_model: "on-demand"

        - id: "s3-archive"
          service: "glacier"
          name: "Historical Archive"
          description: "Long-term archival storage"
          configuration:
            storage_gb: 500000
          cost:
            monthly_estimate: 2000
            currency: "USD"
            breakdown:
              - "Glacier Deep Archive: 500TB × $0.00099/GB = $495"
              - "Glacier Flexible Retrieval: 200TB × $0.0036/GB = $720"
              - "Intelligent-Tiering: 300TB × $0.0025/GB = $750"
              - "Retrieval charges: ~$35"
            pricing_model: "on-demand"

        # Data Warehouse Layer
        - id: "redshift-warehouse"
          service: "redshift"
          name: "Enterprise Data Warehouse"
          description: "Redshift cluster for analytics queries"
          configuration:
            instance_type: "ra3.4xlarge"
            instance_count: 6
            storage_gb: 64000
            multi_az: false
            encryption_enabled: true
            backup_enabled: true
            backup_retention_days: 7
          availability_zones:
            - "us-east-1a"
          cost:
            monthly_estimate: 5840
            currency: "USD"
            breakdown:
              - "Compute: 6 × ra3.4xlarge × 730 hrs × $3.26 = $14,274"
              - "Managed storage: 64TB × $0.024/GB = $1,536"
              - "Concurrency Scaling: ~$500"
              - "Reserved Instance discount (1-yr): -$10,470"
            pricing_model: "reserved-1yr"

        - id: "athena-query"
          service: "athena"
          name: "Serverless Query Engine"
          description: "Ad-hoc SQL queries on S3 data lake"
          cost:
            monthly_estimate: 280
            currency: "USD"
            breakdown:
              - "Data scanned: 7TB × $5/TB = $35"
              - "DML queries: 1M queries × $0.25/M = $250"
              - "Free tier (first 10TB): -$5"
            pricing_model: "on-demand"

        # Machine Learning Layer
        - id: "sagemaker-training"
          service: "sagemaker"
          name: "ML Training Jobs"
          description: "Model training infrastructure"
          runs: ["ml-training"]
          configuration:
            instance_type: "ml.p3.8xlarge"
            instance_count: 4
          cost:
            monthly_estimate: 1250
            currency: "USD"
            breakdown:
              - "Training jobs: 4 × ml.p3.8xlarge × 80 hrs/month × $14.688 = $4,700"
              - "Spot instances (70% discount): -$3,290"
              - "Model storage: 500GB × $0.023 = $11.50"
              - "Data processing: ~$-171.50"
            pricing_model: "spot"

        - id: "sagemaker-inference"
          service: "sagemaker"
          name: "ML Inference Endpoints"
          description: "Real-time model serving"
          configuration:
            instance_type: "ml.m5.xlarge"
            instance_count: 3
            auto_scaling:
              enabled: true
              min: 2
              max: 8
          cost:
            monthly_estimate: 840
            currency: "USD"
            breakdown:
              - "Endpoints: 3 × ml.m5.xlarge × 730 hrs × $0.384 = $841"
            pricing_model: "on-demand"

        # Analytics & BI Layer
        - id: "quicksight-bi"
          service: "quicksight"
          name: "QuickSight Dashboards"
          description: "Business intelligence dashboards"
          runs: ["bi-dashboard"]
          cost:
            monthly_estimate: 480
            currency: "USD"
            breakdown:
              - "Enterprise edition: 20 authors × $18 = $360"
              - "Readers: 100 × $0.30 = $30"
              - "SPICE capacity: 50GB × $0.38 = $19"
              - "Q queries: 1000 × $0.50 = $500"
              - "Free tier: -$429"
            pricing_model: "on-demand"

        # Data Catalog & Governance
        - id: "glue-catalog"
          service: "glue"
          name: "Data Catalog"
          description: "Centralized metadata repository"
          cost:
            monthly_estimate: 65
            currency: "USD"
            breakdown:
              - "Objects stored: 50M × $1/M = $50"
              - "Requests: 10M × $1/M = $10"
              - "Free tier: -$1"
              - "Additional features: $6"
            pricing_model: "on-demand"

        - id: "lake-formation"
          service: "glue"
          name: "Lake Formation"
          description: "Data lake governance and access control"
          cost:
            monthly_estimate: 0
            currency: "USD"
            breakdown:
              - "No additional charge (uses Glue infrastructure)"
            pricing_model: "on-demand"

        # Monitoring & Orchestration
        - id: "step-functions-orchestration"
          service: "step-functions"
          name: "Workflow Orchestration"
          description: "Orchestrates ETL pipeline workflows"
          cost:
            monthly_estimate: 125
            currency: "USD"
            breakdown:
              - "State transitions: 5M × $0.025/1k = $125"
            pricing_model: "on-demand"

        - id: "cloudwatch-data-monitoring"
          service: "cloudwatch"
          name: "Data Pipeline Monitoring"
          description: "Metrics and logs for all pipeline components"
          cost:
            monthly_estimate: 580
            currency: "USD"
            breakdown:
              - "Custom metrics: 1000 × $0.30 = $300"
              - "Logs ingestion: 800GB × $0.50 = $400"
              - "Logs storage: 2TB × $0.03 = $60"
              - "Alarms: 150 × $0.10 = $15"
              - "Insights queries: ~$50"
              - "Free tier: -$245"
            pricing_model: "on-demand"

        # Networking
        - id: "vpc-endpoints"
          service: "privatelink"
          name: "VPC Endpoints"
          description: "Private connectivity to AWS services"
          cost:
            monthly_estimate: 160
            currency: "USD"
            breakdown:
              - "Interface endpoints: 5 × 730 hrs × $0.01 = $36.50"
              - "Data processed: 10TB × $0.01/GB = $100"
              - "Gateway endpoints (S3, DynamoDB): $0"
              - "Additional data transfer: $23.50"
            pricing_model: "on-demand"

        # Security & Compliance
        - id: "kms-encryption"
          service: "kms"
          name: "Encryption Key Management"
          description: "KMS keys for data encryption"
          cost:
            monthly_estimate: 85
            currency: "USD"
            breakdown:
              - "Customer managed keys: 25 × $1 = $25"
              - "API requests: 50M × $0.03/10k = $150"
              - "Free tier (20k requests): -$90"
            pricing_model: "on-demand"

        - id: "cloudtrail-audit"
          service: "cloudtrail"
          name: "Audit Logging"
          description: "Tracks all API calls for compliance"
          cost:
            monthly_estimate: 45
            currency: "USD"
            breakdown:
              - "Management events: included (free)"
              - "Data events: 10M × $0.10/100k = $10"
              - "Insights events: 1M × $0.35/100k = $3.50"
              - "S3 storage for logs: 200GB × $0.023 = $4.60"
              - "CloudWatch Logs delivery: ~$27"
            pricing_model: "on-demand"
          compliance:
            - "SOC2"
            - "ISO27001"

        - id: "macie-pii-detection"
          service: "macie"
          name: "PII Detection"
          description: "Automatically detects sensitive data in S3"
          cost:
            monthly_estimate: 380
            currency: "USD"
            breakdown:
              - "S3 buckets evaluated: 15 × $0.10/bucket = $1.50"
              - "Objects scanned: 100TB × $1/TB = $100"
              - "Automated sensitive data discovery: ~$278.50"
            pricing_model: "on-demand"
          compliance:
            - "GDPR"
            - "HIPAA"

connections:
  - id: "app-to-kinesis-clickstream"
    from: "external-apps"
    to: "kinesis-clickstream"
    type: "stream-write"
    protocol: "HTTPS"
    description: "Applications send clickstream events to Kinesis"
    latency_ms: 20
    requests_per_second: 5000
    bandwidth_mbps: 500
    security:
      encryption_in_transit: true
      authentication_required: true
      authentication_method: "IAM"

  - id: "app-to-kinesis-transactions"
    from: "external-apps"
    to: "kinesis-transactions"
    type: "stream-write"
    protocol: "HTTPS"
    description: "Transaction events streamed to Kinesis"
    latency_ms: 15
    requests_per_second: 2000
    security:
      encryption_in_transit: true
    compliance:
      - "PCI-DSS"

  - id: "kinesis-to-firehose"
    from: "kinesis-clickstream"
    to: "kinesis-firehose-s3"
    type: "stream-read"
    protocol: "HTTPS"
    description: "Firehose consumes from Kinesis"
    bandwidth_mbps: 1000

  - id: "firehose-to-s3-raw"
    from: "kinesis-firehose-s3"
    to: "s3-data-lake-raw"
    type: "file-upload"
    protocol: "S3"
    description: "Raw data delivered to S3 data lake"
    bandwidth_mbps: 800

  - id: "kinesis-to-flink"
    from: "kinesis-clickstream"
    to: "emr-flink-cluster"
    type: "stream-read"
    protocol: "HTTPS"
    description: "Flink processes real-time streams"
    bandwidth_mbps: 1000

  - id: "flink-to-s3-processed"
    from: "emr-flink-cluster"
    to: "s3-data-lake-processed"
    type: "file-upload"
    protocol: "S3"
    description: "Processed data written to S3"
    bandwidth_mbps: 600

  - id: "glue-reads-s3-raw"
    from: "glue-etl"
    to: "s3-data-lake-raw"
    type: "file-download"
    protocol: "S3"
    description: "Glue ETL reads raw data"
    bandwidth_mbps: 2000

  - id: "glue-writes-s3-processed"
    from: "glue-etl"
    to: "s3-data-lake-processed"
    type: "file-upload"
    protocol: "S3"
    description: "Glue writes transformed data"
    bandwidth_mbps: 1500

  - id: "spark-reads-s3"
    from: "emr-spark-batch"
    to: "s3-data-lake-processed"
    type: "file-download"
    protocol: "S3"
    description: "Spark batch jobs read processed data"
    bandwidth_mbps: 3000

  - id: "spark-writes-redshift"
    from: "emr-spark-batch"
    to: "redshift-warehouse"
    type: "database-query"
    protocol: "SQL"
    description: "Spark loads data into Redshift"
    bandwidth_mbps: 1000

  - id: "s3-to-redshift"
    from: "s3-data-lake-processed"
    to: "redshift-warehouse"
    type: "database-query"
    protocol: "HTTPS"
    description: "Redshift COPY from S3"
    bandwidth_mbps: 2000

  - id: "athena-queries-s3"
    from: "athena-query"
    to: "s3-data-lake-processed"
    type: "file-download"
    protocol: "S3"
    description: "Athena queries S3 data"
    latency_ms: 500

  - id: "sagemaker-training-reads-s3"
    from: "sagemaker-training"
    to: "s3-data-lake-processed"
    type: "file-download"
    protocol: "S3"
    description: "ML training reads feature data"
    bandwidth_mbps: 500

  - id: "redshift-to-sagemaker"
    from: "redshift-warehouse"
    to: "sagemaker-training"
    type: "database-query"
    protocol: "SQL"
    description: "Training data exported from Redshift"
    bandwidth_mbps: 200

  - id: "flink-to-sagemaker-inference"
    from: "emr-flink-cluster"
    to: "sagemaker-inference"
    type: "api-call"
    protocol: "HTTPS"
    description: "Real-time predictions during stream processing"
    latency_ms: 150
    requests_per_second: 100

  - id: "quicksight-to-redshift"
    from: "quicksight-bi"
    to: "redshift-warehouse"
    type: "database-query"
    protocol: "SQL"
    description: "QuickSight queries Redshift for dashboards"
    latency_ms: 2000

  - id: "quicksight-to-athena"
    from: "quicksight-bi"
    to: "athena-query"
    type: "database-query"
    protocol: "SQL"
    description: "QuickSight queries S3 via Athena"
    latency_ms: 5000

  - id: "step-functions-orchestrates-glue"
    from: "step-functions-orchestration"
    to: "glue-etl"
    type: "api-call"
    protocol: "HTTPS"
    description: "Step Functions triggers Glue jobs"

  - id: "step-functions-orchestrates-emr"
    from: "step-functions-orchestration"
    to: "emr-spark-batch"
    type: "api-call"
    protocol: "HTTPS"
    description: "Step Functions manages EMR clusters"

  - id: "s3-to-glacier"
    from: "s3-data-lake-raw"
    to: "s3-archive"
    type: "replication"
    protocol: "S3"
    description: "Lifecycle policy archives old data to Glacier"
    bandwidth_mbps: 100

cost:
  total_monthly: 23580
  currency: "USD"
  by_service:
    compute: 7100
    storage: 5450
    database: 6120
    streaming: 1055
    ml: 2090
    networking: 160
    monitoring: 580
    security: 510
    orchestration: 125
    bi: 480
  by_environment:
    production: 23580
  notes:
    - "Costs based on us-east-1 pricing as of January 2025"
    - "EMR Spark uses 70% spot instances for significant savings"
    - "Redshift using 1-year Reserved Instances (65% savings)"
    - "S3 Intelligent-Tiering automatically optimizes storage costs"
    - "Consider Savings Plans for additional 10-15% compute savings"
    - "Data transfer costs are ~$800/month (included in service breakdowns)"
    - "Peak processing hours may increase EMR costs by 30-40%"